{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-bronze",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-greece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neo4j import GraphDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-marble",
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph, Node, Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-castle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo.bulk import merge_nodes, create_nodes, create_relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-removal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "from time import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-portal",
   "metadata": {},
   "source": [
    "## Connect to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-interim",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"bolt://localhost:7687\"\n",
    "user = \"neo4j\"\n",
    "pword = \"localadmin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-missouri",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph(uri, user=user, password=pword)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-handy",
   "metadata": {},
   "source": [
    "## Load up judges and add them to the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "jdf = pd.read_csv('../data/judges_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-reliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "jdf[\"start_date\"] = pd.to_datetime(jdf[\"start_date\"])\n",
    "jdf[\"end_date\"] = pd.to_datetime(jdf[\"end_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-commander",
   "metadata": {},
   "outputs": [],
   "source": [
    "jdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "jdf.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-trace",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\" if pd.isnull(jdf.iloc[3][\"end_date\"]) else jdf.iloc[3][\"end_date\"].strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-cartoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_commit_judges(start_row=0, end_row=len(jdf)):\n",
    "    keys = [\"judge_id\", \"judge_position\", \"judge_female\", \"judge_start\", \"judge_end\"]\n",
    "    jslice = jdf[start_row:end_row].iterrows()\n",
    "    s1 = time()\n",
    "    data = [\n",
    "        [row[\"ddl_judge_id\"], \n",
    "         row[\"judge_position\"], \n",
    "         row[\"female_judge\"],\n",
    "         row[\"start_date\"].strftime(\"%Y-%m-%d\"),\n",
    "         \"\" if pd.isnull(row[\"end_date\"]) else row[\"end_date\"].strftime(\"%Y-%m-%d\")\n",
    "        ]\n",
    "    for index, row in jslice]\n",
    "    e1 = time()\n",
    "    #print(\"Time to process list: \", e1 - s1)\n",
    "    s2 = time()\n",
    "    create_nodes(graph.auto(), data, labels={\"Judge\"}, keys=keys)\n",
    "    e2 = time()\n",
    "    # print(\"Time to do TX: \", e2 - s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-prompt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_judges(batch_size=10000, delete_first=False):\n",
    "    gc.collect() # just being cautious, given size of things being handed around\n",
    "    if delete_first:\n",
    "        graph.run(\"match (n: Judge) detach delete n\")\n",
    "    for batch in range(0, ceil(len(jdf)/batch_size)):\n",
    "        print(\"Adding judges, batch: \", batch)\n",
    "        manual_commit_judges(start_row=batch * batch_size, end_row = (batch + 1) * batch_size)\n",
    "    print(\"Completed, number judges: \", graph.nodes.match(\"Judge\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-place",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not necessary, but would be analogue of above\n",
    "load_judges_query = \"\"\"\n",
    "    load csv with headers from \"file:///judges_clean.csv\" as row\n",
    "    with \n",
    "        toInteger(row.ddl_judge_id) as judge_id, \n",
    "        row.judge_position as judge_position, \n",
    "        toInteger(row.state_code) as judge_state_code,\n",
    "        toInteger(row.dist_code) as judge_dist_code,\n",
    "        toInteger(row.court_no) as judge_court_no,\n",
    "        row.female_judge as judge_female,\n",
    "        apoc.date.parse(row.start_date, \"ms\", \"dd-MM-yyyy\") as judgeStartMs,\n",
    "        apoc.date.parse(row.end_date, \"ms\", \"dd-MM-yyyy\") as judgeEndMs,\n",
    "    return judge_id, judget_position, judge_state_code, judge_dist_code, judge_cour_no, judge_female limit 10;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-deposit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _very_ necessary\n",
    "# graph.run(\"CREATE CONSTRAINT idx_judge_id ON (judge:Judge) ASSERT judge.judge_id IS UNIQUE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-differential",
   "metadata": {},
   "source": [
    "## Now load some cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-wiring",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_reader = pd.read_csv('../data/cases/cases_2018.csv', iterator=True)\n",
    "first_cases = case_reader.get_chunk(1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-custom",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-alexandria",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = first_cases\n",
    "cdf[\"date_of_filing\"] = pd.to_datetime(cdf[\"date_of_filing\"])\n",
    "cdf[\"date_of_decision\"] = pd.to_datetime(cdf[\"date_of_decision\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-knife",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_commit_cases(df, start_row=0, end_row=len(jdf)):\n",
    "    keys = [\"case_id\", \"year\", \"state_code\", \"dist_code\", \"court_no\", \"judge_position\", \"date_of_filing\", \"date_of_decision\"]\n",
    "    cslice = df[start_row:end_row].iterrows()\n",
    "    s1 = time()\n",
    "    data = [\n",
    "        [row[\"ddl_case_id\"], \n",
    "         row[\"year\"], \n",
    "         row[\"state_code\"],\n",
    "         row[\"dist_code\"],\n",
    "         row[\"court_no\"],\n",
    "         row[\"judge_position\"],\n",
    "         row[\"date_of_filing\"].strftime(\"%Y-%m-%d\"),\n",
    "         \"\" if pd.isnull(row[\"date_of_decision\"]) else row[\"date_of_decision\"].strftime(\"%Y-%m-%d\")\n",
    "        ]\n",
    "    for index, row in cslice]\n",
    "    e1 = time()\n",
    "    #print(\"Time to process list: \", e1 - s1)\n",
    "    s2 = time()\n",
    "    create_nodes(graph.auto(), data, labels={\"Case\"}, keys=keys)\n",
    "    e2 = time()\n",
    "    # print(\"Time to do TX: \", e2 - s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-registration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def commit_cases_df(cdf, batch_size=50000, delete_first=False):\n",
    "    gc.collect()\n",
    "    if delete_first:\n",
    "        graph.run(\"match (n: Case) detach delete n\")\n",
    "    \n",
    "    for batch in range(0, ceil(len(cdf)/batch_size)):\n",
    "        print(\"Loading cases, batch: \", batch)\n",
    "        manual_commit_cases(cdf, start_row=batch * batch_size, end_row = (batch + 1) * batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-sound",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB\n",
    "# graph.run(\"CREATE CONSTRAINT idx_case_id ON (case:Case) ASSERT case.case_id IS UNIQUE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-wichita",
   "metadata": {},
   "source": [
    "## Heavy lift: judge-case relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-fountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to add some relationships\n",
    "df = pd.read_csv('../data/keys/judge_case_merge_key.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-bennett",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = df[df.ddl_case_id.isin(cdf.ddl_case_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# free up memory for what comes next\n",
    "# del df\n",
    "# del cdf\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-rebecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-marketplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_relationships = len(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-master",
   "metadata": {},
   "outputs": [],
   "source": [
    "major_batch_size = 10000\n",
    "minor_batch_size = 20\n",
    "number_in_graph = graph.run(\"match ()-[r:JUDGED]->() return count(r) as count\").evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-webcam",
   "metadata": {},
   "outputs": [],
   "source": [
    "while number_in_graph < number_relationships:\n",
    "    start_index = number_in_graph\n",
    "    end_index = start_index + major_batch_size\n",
    "    print(f\"Adding relationships from {start_index} to {end_index}\")\n",
    "    data = [\n",
    "        (row[\"ddl_filing_judge_id\"], { \"type\": \"FILING_JUDGE\" }, row[\"ddl_case_id\"])\n",
    "        for index, row in sdf[start_index:end_index].iterrows()\n",
    "    ]\n",
    "    \n",
    "    for i in range(ceil(len(data) / minor_batch_size)):\n",
    "        if i % 10 == 0:\n",
    "            print(\".\", end=\"\")\n",
    "\n",
    "        create_relationships(graph.auto(), data[i * minor_batch_size:(i + 1) * minor_batch_size], \n",
    "                             \"JUDGED\", start_node_key=(\"Judge\", \"judge_id\"), end_node_key=(\"Case\", \"case_id\"))\n",
    "    \n",
    "    number_in_graph = graph.run(\"match ()-[r:JUDGED]->() return count(r) as count\").evaluate()\n",
    "    print(\"Completed a major addition, number in graph now: \", number_in_graph)\n",
    "\n",
    "print(\"Complete! Number in graph: \", number_in_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-flash",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_in_graph = graph.run(\"match ()-[r:JUDGED]->() return count(r) as count\").evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-federation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"In graph: \", number_in_graph, \" and in frame: \", len(sdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-slide",
   "metadata": {},
   "source": [
    "## Load in the acts and sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_acts_to_graph(df, row_keys, node_keys, start_row=0, end_row=None):\n",
    "    cslice = df[start_row:end_row].iterrows()\n",
    "    data = [[row[key] for key in row_keys] for index, row in cslice]\n",
    "    print(\"Assembled list, adding to graph\")\n",
    "    create_nodes(graph.auto(), data, labels={\"Act\"}, keys=node_keys)\n",
    "    # print(\"Time to do TX: \", e2 - s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-machine",
   "metadata": {},
   "outputs": [],
   "source": [
    "acts = pd.read_csv('../data/keys/act_key.csv')\n",
    "acts = acts[3:] # first rows are NA and ' and \"\n",
    "acts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-convenience",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_df_keys = [\"act\", \"count\", \"act_s\"]\n",
    "node_keys = [\"act_id\", \"total_count\", \"act_sum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_acts_to_graph(df=acts, row_keys=act_df_keys, node_keys=node_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-dallas",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-packing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# create index idx_act_id for (a:Act) on (a.act_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are _a lot_ of these, and all are central, so distort things, so remove\n",
    "criminal_procedure_variants = [\n",
    "    \"CODE OF CRIMINAL PROCEDURE, 1973\",\n",
    "    \"Code of Criminal Procedure, 1973\",\n",
    "    \"Code of Criminal Procedure 1973\",\n",
    "    \"CODE OF CRIMINAL PROCEDURE\",\n",
    "    \"Criminal Procedure Code\",\n",
    "    \"Code of Criminal Procedure, 1973 1974\",\n",
    "    \"CodeofCriminalProcedure\",\n",
    "    \"Cr.P.C. \",\n",
    "    \"Code of Criminal Procedure\",\n",
    "    \"2.Code of Criminal Procedure, 1973\",\n",
    "    \"Cr.P.C.\",\n",
    "    \"Cr.P.C\",\n",
    "    \"Cr.P.c\",\n",
    "    \"CR.P.C\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-union",
   "metadata": {},
   "source": [
    "## Now do act-section relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-regular",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_start = 0\n",
    "number_rows = 5e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-republican",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_case_df = pd.read_csv('../data/acts_sections.csv', nrows=number_rows, skiprows=read_start)\n",
    "# first_acts = act_reader.get_chunk(number_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_case_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-webcam",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf = act_case_df[act_case_df.ddl_case_id.isin(cdf.ddl_case_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_rels = lambda reltype: graph.run(f\"match ()-[r:{reltype}]->() return count(r) as count\").evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of acts in DF: ', len(adf))\n",
    "print('Number of relationships: ', count_rels('USES_ACT'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_batch_act_relationships(relationship_type=\"USES_ACT\", minor_batch_size=20, major_batch_size=1000, offset=0):\n",
    "    number_acts = count_rels(relationship_type)\n",
    "    start_index = number_acts\n",
    "    end_index = start_index + major_batch_size\n",
    "    print(f\"Adding relationships of type {relationship_type} from {start_index} to {end_index}\")\n",
    "    data = [\n",
    "        (row[\"ddl_case_id\"], { \"type\": relationship_type }, row[\"act\"])\n",
    "        for index, row in adf[start_index:end_index].iterrows()\n",
    "    ]\n",
    "    \n",
    "    start_time = time()\n",
    "    for i in range(ceil(len(data) / minor_batch_size)):\n",
    "        if i % 2 == 0:\n",
    "            print(\".\", end=\"\")\n",
    "            \n",
    "        if i % 5 == 0:\n",
    "            print(\"Elapsed time: \", int(time() - start_time))\n",
    "\n",
    "        create_relationships(graph.auto(), \n",
    "                             data[i * minor_batch_size:(i + 1) * minor_batch_size], \n",
    "                             relationship_type, \n",
    "                             start_node_key=(\"Case\", \"case_id\"), \n",
    "                             end_node_key=(\"Act\", \"act_id\"))\n",
    "    \n",
    "    number_in_graph = count_rels(relationship_type)\n",
    "    print(\"Completed a major addition, number in graph now: \", number_in_graph, \" took: \", time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-commissioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_batch_act_relationships(minor_batch_size=1000, major_batch_size=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-blank",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legalgraph",
   "language": "python",
   "name": "legalgraph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
