{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-bronze",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-palestine",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lg_utils import connect_to_graph, count_nodes, count_rels, load_csv, add_csv_to_graph, add_relationships, add_nodes_df_to_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-missouri",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = connect_to_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-message",
   "metadata": {},
   "source": [
    "## Initial counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-weekly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current counts\n",
    "number_judges = count_nodes(graph, \"Judge\")\n",
    "number_cases = count_nodes(graph, \"Case\")\n",
    "number_acts = count_nodes(graph, \"Act\")\n",
    "\n",
    "number_judge_rel = count_rels(graph, \"JUDGED\")\n",
    "number_act_rel = count_rels(graph, \"USES_ACT\")\n",
    "\n",
    "# 13724299\n",
    "print(f\"In graph: judges: {number_judges}, cases: {number_cases}, acts: {number_acts}, judge-case rels: {number_judge_rel}, case-act rels: {number_act_rel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-handy",
   "metadata": {},
   "source": [
    "## Load judges and add them to the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "jdf = load_csv('../data/judges_clean.csv', datetime_keys=[\"start_date\", \"end_date\"], number_rows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "jdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_graph_properties = [\"judge_id\", \"judge_position\", \"judge_female\", \"judge_start\", \"judge_end\"]\n",
    "judge_df_keys = [\"ddl_judge_id\", \"judge_position\", \"female_judge\", \"start_date_str\", \"end_date_str\"]\n",
    "judge_index = {\"index_name\": \"idx_judge_id\", \"index_key\": \"judge_id\"}\n",
    "\n",
    "add_judges = False\n",
    "if add_judges:\n",
    "    add_csv_to_graph(\n",
    "        graph=graph,\n",
    "        csv_file=\"../data/judges_clean.csv\",\n",
    "        label=\"Judge\",\n",
    "        merge_key=(\"Judge\", \"judge_id\"),\n",
    "        graph_keys=judge_graph_properties,\n",
    "        df_keys=judge_df_keys,\n",
    "        index_to_add=judge_index\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-differential",
   "metadata": {},
   "source": [
    "## Load cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-strike",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = load_csv('../data/cases/cases_2018.csv', datetime_keys=[\"date_of_filing\", \"date_of_decision\"], number_rows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-dining",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_graph_properties = [\n",
    "    \"case_id\", \"year\", \"state_code\", \"dist_code\", \"court_no\", \"judge_position\", \"date_of_filing\", \"date_of_decision\",\n",
    "    \"female_defendant\", \"female_adv_defendant\", \"female_adv_pet\", \"type_name\", \"purpose_name\", \"disp_name\"\n",
    "]\n",
    "df_column_keys = [\n",
    "    \"ddl_case_id\", \"year\", \"state_code\", \"dist_code\", \"court_no\", \"judge_position\", \"date_of_filing_str\", \"date_of_decision_str\",\n",
    "    \"female_defendant\", \"female_adv_def\", \"female_adv_pet\", \"type_name\", \"purpose_name\", \"disp_name\"\n",
    "]\n",
    "\n",
    "add_cases = True # flip to false to initiate\n",
    "if add_cases:\n",
    "    add_csv_to_graph(\n",
    "        graph=graph,\n",
    "        csv_file=\"../data/cases/cases_2018.csv\",\n",
    "        label=\"Case\",\n",
    "        merge_key=(\"Case\", \"case_id\"),\n",
    "        graph_keys=case_graph_properties,\n",
    "        df_keys=df_column_keys,\n",
    "        datetime_keys=[\"date_of_filing\", \"date_of_decision\"],\n",
    "        index_to_add={\"index_name\": \"idx_case_id\", \"index_key\": \"case_id\"},\n",
    "        use_merge=True,\n",
    "        assume_all_merge=True # since property update\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-wichita",
   "metadata": {},
   "source": [
    "## Wire up judge-case relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_case_ids = pd.read_csv('../data/cases/cases_2018.csv', usecols=['ddl_case_id'])\n",
    "\n",
    "number_relationships = count_total_rows('../data/judge_case_merge_key.csv')\n",
    "number_in_graph = count_rels(graph, \"JUDGED\")\n",
    "print(\"Number relationships in data: \", number_relationships, \" and in graph: \", number_in_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_rel_keys = [(\"Judge\", \"judge_id\"), (\"Case\", \"case_id\")]\n",
    "rel_df_keys = [\"ddl_filing_judge_id\", \"ddl_case_id\"]\n",
    "prop_dict = { \"type\": \"FILING_JUDGE\" }\n",
    "\n",
    "add_judge_rels = False\n",
    "if add_judge_rels:\n",
    "    add_relationships(\n",
    "        graph=graph, \n",
    "        join_csv_file='../data/judge_case_merge_key.csv', \n",
    "        relationship_type=\"FILING\",\n",
    "        existence_id_series=all_case_ids.ddl_case_id, \n",
    "        existence_id_key=\"ddl_case_id\",                     \n",
    "        graph_keys=graph_rel_keys, \n",
    "        rel_keys=rel_df_keys, \n",
    "        prop_dict=prop_dict,\n",
    "        df_start=df_read_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-aberdeen",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_in_graph = count_rels(graph, \"JUDGED\")\n",
    "print(\"Number in graph: \", number_in_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-slide",
   "metadata": {},
   "source": [
    "## Load in the acts and sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_properties = [\"act_id\", \"total_count\", \"act_sum\"]\n",
    "act_df_keys = [\"act\", \"count\", \"act_s\"]\n",
    "act_index = {\"index_name\": \"idx_act_id\", \"index_key\": \"act_id\"}\n",
    "\n",
    "add_acts = False\n",
    "max_iter = None\n",
    "if add_acts:\n",
    "    acts_raw = pd.read_csv('../data/keys/act_key.csv')\n",
    "    acts_raw = acts[3:] # first rows are NA and ' and \"\n",
    "    acts.to_csv('../data/acts.csv')\n",
    "    \n",
    "    add_csv_to_graph(\n",
    "        graph=graph,\n",
    "        csv_file=\"../data/acts.csv\",\n",
    "        label=\"Act\",\n",
    "        merge_key=(\"Act\", \"act_id\"),\n",
    "        graph_keys=act_properties,\n",
    "        df_keys=act_df_keys,\n",
    "        index_to_add=act_index,\n",
    "        max_iter=max_iter\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are _a lot_ of these, and all are central, so distort things, so remove\n",
    "criminal_procedure_variants = [\n",
    "    \"CODE OF CRIMINAL PROCEDURE, 1973\",\n",
    "    \"Code of Criminal Procedure, 1973\",\n",
    "    \"Code of Criminal Procedure 1973\",\n",
    "    \"CODE OF CRIMINAL PROCEDURE\",\n",
    "    \"Criminal Procedure Code\",\n",
    "    \"Code of Criminal Procedure, 1973 1974\",\n",
    "    \"CodeofCriminalProcedure\",\n",
    "    \"Cr.P.C. \",\n",
    "    \"Code of Criminal Procedure\",\n",
    "    \"2.Code of Criminal Procedure, 1973\",\n",
    "    \"Cr.P.C.\",\n",
    "    \"Cr.P.C\",\n",
    "    \"Cr.P.c\",\n",
    "    \"CR.P.C\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-union",
   "metadata": {},
   "source": [
    "## Now do case-act relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_act_section_rels = count_total_rows('../data/acts_sections.csv')\n",
    "rels_in_graph = count_rels('USES_ACT')\n",
    "print('Number of total relationships: ', total_act_section_rels, ' and in graph: ', rels_in_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-blank",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read_start = number_in_graph\n",
    "last_stop = 60020612 # where last stopped - a little manual for now\n",
    "df_read_start = int(last_stop + rows_per_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-sunday",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_rel_keys = [(\"Case\", \"case_id\"), (\"Act\", \"act_id\")]\n",
    "rel_df_keys = [\"ddl_case_id\", \"act\"]\n",
    "\n",
    "add_case_act_rels = False\n",
    "if add_case_act_rels:\n",
    "    add_relationships(\n",
    "        graph=graph, \n",
    "        join_csv_file='../data/acts_sections.csv', \n",
    "        relationship_type=\"USES_ACT\",\n",
    "        target_id_series=all_case_ids.ddl_case_id, \n",
    "        target_id_key=\"ddl_case_id\",                     \n",
    "        graph_keys=graph_rel_keys, \n",
    "        rel_keys=rel_df_keys, \n",
    "        df_start=df_read_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-cigarette",
   "metadata": {},
   "source": [
    "## Loading remainder of entities and relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-harmony",
   "metadata": {},
   "source": [
    "What we have:\n",
    "\n",
    "* States and districts (for doing subgraphs): state_code, dist_code\n",
    "* Gender properties (similar): female_defendant, female_adv_defendant, female_adv_pet\n",
    "* Type (type_name), purpose (purpose_name), dispensation (disp_name)\n",
    "* Sections: but with just the raw text, _not_ with the act in the section file, so will have to reconstruct that\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-method",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = pd.read_csv('../data/keys/cases_state_key.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-dealer",
   "metadata": {},
   "outputs": [],
   "source": [
    "states.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "states.state_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = states.groupby('state_name').state_code.apply(set).apply(lambda value: list(value)[0]).reset_index(name='state_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.sort_values('state_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_states = False\n",
    "\n",
    "if add_states:\n",
    "    add_nodes_df_to_graph(graph, sdf, \"State\", merge_key=(\"State\", \"state_id\"), \n",
    "                      graph_keys=[\"state_id\", \"state_name\"], df_keys=[\"state_code\", \"state_name\"],\n",
    "                     index_to_add={\"index_name\": \"idx_state_id\", \"index_key\": \"state_id\"})\n",
    "    graph.run(\"create index case_state_idx for (c:Case) on (c.state_code)\").evaluate()\n",
    "    graph.run(\"\"\"\n",
    "        call apoc.periodic.iterate(\n",
    "        \"match (c:Case), (s:State) where c.state_code = s.state_id return c, s\", \n",
    "        \"create (c)-[:IN_STATE]->(s)\", \n",
    "        {batchSize: 10000, parallel: true})\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-winner",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_rels(graph, \"IN_STATE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-valuable",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.run(\"match (c:Case) return c limit 1\").evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-parts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note, had to clean up by renaming:\n",
    "# Karnataka district 30, one instance of YADGIR to YADGIR.\n",
    "# Rajasthan, Jaipur Metro to Jaipur Metro I\n",
    "# Punjab, Hoshiarpur to Hoshiarpurr\n",
    "districts = pd.read_csv('../data/keys/cases_district_key_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-approval",
   "metadata": {},
   "outputs": [],
   "source": [
    "districts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-interpretation",
   "metadata": {},
   "outputs": [],
   "source": [
    "districts['combined_name'] = districts['state_name'] + '_' + districts['district_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-completion",
   "metadata": {},
   "outputs": [],
   "source": [
    "districts['combined_code'] = districts['state_code'] * 100 + districts['dist_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invalid-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Max names per code: ', max(districts.groupby('combined_code')['combined_name'].nunique())) # check these do not vary over years and do not duplicate\n",
    "print('Max codes per name: ', max(districts.groupby('combined_name')['combined_code'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-advertising",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_districts = False\n",
    "\n",
    "if add_districts:\n",
    "    add_nodes_df_to_graph(graph, districts, \"District\", merge_key=(\"District\", \"district_id\"), \n",
    "                          graph_keys=[\"district_id\", \"district_name\", \"state_id\", \"ws_dist_id\", \"ws_dist_name\"], \n",
    "                          df_keys=[\"combined_code\", \"combined_name\", \"state_code\", \"dist_code\", \"district_name\"],\n",
    "                          index_to_add={\"index_name\": \"idx_district_id\", \"index_key\": \"district_id\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-deviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_case_districts = False\n",
    "set_dist_code_query = \"\"\"\n",
    "    call apoc.periodic.iterate(\n",
    "        \"match (c:Case) return c\", \n",
    "        \"set c.district_id = 100 * c.state_code + c.dist_code\", \n",
    "        {batchSize: 100000, parallel: true}\n",
    "        )\n",
    "\"\"\"\n",
    "\n",
    "create_case_district_rels = \"\"\"\n",
    "    call apoc.periodic.iterate(\n",
    "        \"match (c:Case), (d:District) where c.district_id = d.district_id return c, d\",\n",
    "        \"create (c)-[:IN_DISTRICT]->(d)\",\n",
    "        {batchSize: 10000, parallel: true}\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "create_state_district_rels = \"match (s:State), (d:District) where s.state_id = d.state_id create (s)-[:CONTAINS]->(d)\"\n",
    "\n",
    "if add_case_districts:\n",
    "    graph.run(set_dist_code_query).evaluate()\n",
    "    graph.run(\"create index case_district_idx for (c:Case) on (c.district_id)\").evaluate()\n",
    "    graph.run(create_case_district_rels).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handy-labor",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of case-district: \", count_rels(graph, \"IN_DISTRICT\"), \" and state-district: \", count_rels(graph, \"CONTAINS\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these property loads are large, and should rather be done by load_csv in Cypher - incorporate up top in future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-turkish",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legalgraph",
   "language": "python",
   "name": "legalgraph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
